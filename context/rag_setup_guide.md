# Interview RAG System Setup and Usage
*generated by Claude 3.5 Sonnet

This guide explains how to set up and use the Interview RAG (Retrieval-Augmented Generation) system, which is based on the PydanticAI RAG example but adapted for organizational interview insights.

## What This System Does

The Interview RAG system allows you to:
- Store interview transcripts and responses in a vector database
- Ask natural language questions about organizational insights
- Get AI-powered answers based on actual interview data
- Track sentiment trends across teams
- Identify recurring issues and themes

## Prerequisites

1. **PostgreSQL with pgvector**: You need a PostgreSQL database with the pgvector extension
2. **OpenAI API Key**: For generating embeddings and running the AI agent
3. **Python Dependencies**: Already included in the project's `pyproject.toml`

## Setup Instructions

### 1. Start PostgreSQL with pgvector

Use Docker to run PostgreSQL with pgvector (this matches the PydanticAI example):

```bash
mkdir postgres-data
docker run --rm \
  -e POSTGRES_PASSWORD=postgres \
  -p 54320:5432 \
  -v `pwd`/postgres-data:/var/lib/postgresql/data \
  pgvector/pgvector:pg17
```

### 2. Set Environment Variables

Make sure you have your OpenAI API key set:

```bash
export OPENAI_API_KEY="your-openai-api-key-here"
```

### 3. Install Dependencies

Install the project dependencies:

```bash
pip install -e .
```

### 4. Set Up the Database Schema

Create the database and tables:

```bash
python -m newsletters.cli setup-rag
```

### 5. Create Sample Data (Optional)

To test the system with sample interview data:

```bash
python -m newsletters.cli create-samples
```

## Usage Examples

### Ask Questions About Interviews

```bash
# Basic question about frustrations
python -m newsletters.cli ask "What are the main frustrations people are experiencing?"

# Team-specific questions
python -m newsletters.cli ask "How is the Engineering team doing?"

# Trend analysis
python -m newsletters.cli ask "What are the recurring issues across all teams?"

# Positive insights
python -m newsletters.cli ask "What wins and successes have people shared recently?"
```

### Example Questions You Can Ask

- "What are the biggest blockers affecting productivity?"
- "How is team morale across different departments?"
- "What tools or processes are causing the most frustration?"
- "What improvements have people suggested?"
- "Are there any communication issues between teams?"
- "What are people most excited about?"

## How It Works

### Data Model

The system uses Pydantic models for:
- `Person`: Represents individuals in the organization
- `Interview`: Complete interview with metadata
- `QuestionResponse`: Individual Q&A pairs
- `InterviewMetadata`: Additional context and tags

### Vector Search

1. **Embedding Generation**: Interview content is converted to vector embeddings using OpenAI's `text-embedding-3-small` model
2. **Storage**: Embeddings are stored in PostgreSQL with pgvector for efficient similarity search
3. **Retrieval**: When you ask a question, the system:
   - Converts your question to an embedding
   - Finds similar interview content using vector similarity
   - Provides relevant interviews to the AI agent as context

### Agent Tools

The PydanticAI agent has access to three tools:
1. `retrieve_interviews`: Semantic search through interview content
2. `get_team_sentiment_trends`: Time-based sentiment analysis for teams
3. `find_recurring_issues`: Find patterns and recurring themes

## Adding Real Interview Data

To add real interview data to the system, use the `store_interview_embedding()` function:

```python
from newsletters.interview_rag import store_interview_embedding, Interview, Person, QuestionResponse, InterviewMetadata
from datetime import datetime

# Create interview object
interview = Interview(
    timestamp=datetime.now(),
    interviewer=Person(name="Manager", email="manager@company.com", team="Leadership", role="Manager"),
    interviewee=Person(name="Employee", email="employee@company.com", team="Engineering", role="Developer"),
    context="weekly_checkin",
    questions=[
        QuestionResponse(
            question_id="1",
            question_text="How was your week?",
            response_text="It was good, but the deployment process is still causing delays.",
            response_sentiment=-0.2
        )
    ],
    metadata=InterviewMetadata(duration_minutes=15.0, tags=["weekly", "checkin"]),
    sentiment_analysis=0.1
)

# Store in database
await store_interview_embedding(interview)
```

## Architecture Notes

This implementation follows the PydanticAI RAG example pattern:
- Uses the same PostgreSQL + pgvector setup
- Similar embedding and retrieval patterns
- Async/await throughout for performance
- Type-safe with Pydantic models

The key adaptation is that instead of documentation sections, we're embedding and searching interview content for organizational insights.

## Next Steps

1. **Integration with Transcription Services**: Connect with Teams, Zoom, etc. for automatic transcription
2. **Sentiment Analysis**: Add more sophisticated sentiment analysis
3. **Trend Visualization**: Create dashboards for trend analysis
4. **Privacy Controls**: Add role-based access and anonymization
5. **Automated Insights**: Generate regular reports automatically
